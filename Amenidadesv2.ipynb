{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP2oRTBIRN2pNb7tSYBhcYA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","import json\n","import polars as pl\n","import pandas as pd\n","import re\n","from collections import Counter\n","\n","drive.mount('/content/drive')\n","ubicaciones = ['review-Florida_parquet', 'review-New_York_parquet']\n","carpetas = {'review-Florida_parquet': 19, 'review-New_York_parquet': 18}\n","palabras_a_buscar = ['wifi', 'gym', 'restaurant', 'piscina', 'laundry', 'kindergarten', 'pool', 'parking lot',\n","                     'massage', 'casino', 'resort', 'fitness', 'tennis', 'taxi', 'Swimming', 'food', 'parking', 'central heating', 'central heat']\n","\n","def leer_y_procesar_parquet(ubicaciones, carpetas):\n","    dfs = []\n","\n","    # Función para leer y convertir un archivo Parquet\n","    def leer_y_convertir_parquet(n, ubicacion):\n","        file_path = f'/content/drive/MyDrive/reviews/{ubicacion}/{n}.parquet'\n","        df = pl.read_parquet(file_path)\n","        df_pandas = df.to_pandas()\n","        return df_pandas\n","\n","    # Leer y procesar los archivos Parquet\n","    for ubicacion in ubicaciones:\n","        for i in range(1, carpetas[ubicacion] + 1):\n","            df = leer_y_convertir_parquet(str(i), ubicacion)\n","            dfs.append(df)\n","\n","    # Concatenar todos los DataFrames en uno solo\n","    df1 = pd.concat(dfs)\n","    df1 = df1[['text', 'gmap_id']]\n","    ruta2 = '/content/drive/MyDrive/reviews/hoteles.csv'\n","    df2 = pd.read_csv(ruta2)\n","    df2 = df2[['name', 'gmap_id', 'City', 'State', 'url']]\n","    df = pd.merge(df2, df1, on='gmap_id', how='left')\n","    df = df.dropna(subset=['text'])\n","    df['amenidades'] = ''\n","    return df\n","\n","\n","def extraer_amenidades(df, palabras_a_buscar):\n","    # Iterar sobre cada fila del DataFrame\n","    for index, row in df.iterrows():\n","        texto = row['text']\n","\n","        # Verificar si el texto no es None\n","        if texto is not None:\n","            # Inicializar una lista vacía para almacenar las amenidades encontradas\n","            amenidades_encontradas = []\n","\n","            # Buscar palabras clave de amenidades en el texto y agregarlas a la lista de amenidades encontradas\n","            for palabra in palabras_a_buscar:\n","                if palabra in texto:\n","                    amenidades_encontradas.append(palabra)\n","\n","            # Asignar la lista de amenidades encontradas a la columna 'amenidades' para esta fila\n","            df.at[index, 'amenidades'] = amenidades_encontradas\n","        else:\n","            # Si el texto es None, asignar una lista vacía a 'amenidades'\n","            df.at[index, 'amenidades'] = []\n","\n","    # Eliminar filas duplicadas basadas en el gmap_id\n","    df = df.drop_duplicates(subset=['gmap_id'])\n","\n","    return df\n","\n","df_final = leer_y_procesar_parquet(ubicaciones, carpetas)\n","final=extraer_amenidades(df_final, palabras_a_buscar)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DfdGEGhCPy-P","executionInfo":{"status":"ok","timestamp":1708616936010,"user_tz":180,"elapsed":9740,"user":{"displayName":"Carlos Hidalgo","userId":"09076855611341336673"}},"outputId":"ff4b9d43-57c2-4da3-c8e3-f3fb6ddd2bc2"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]}]}